{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seq2Seq.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOQI4Ea3QyUt9xKN7gYRqbg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/banjodayo39/deep_learning_project/blob/master/Seq2Seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yv8ONJLhGn-n",
        "colab_type": "text"
      },
      "source": [
        "Import Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noIr1Vb7LW3p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import LSTM, GRU, Input, Dense, Embedding\n",
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt \n",
        "import numpy as np "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hj_OHusK2G8O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "82c702fb-f08a-4241-86fd-d288f750a57d"
      },
      "source": [
        "import keras.backend as K\n",
        "if len(K.tensorflow_backend._get_available_gpus()) > 0:\n",
        "  from keras.layers import CuDNNLSTM as LSTM\n",
        "  from keras.layers import CuDNNGRU as GRU\n",
        "  print(\"Yes\")"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Yes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFOQBFSTHXwG",
        "colab_type": "text"
      },
      "source": [
        "Config Hyp"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkMFlzD3HOTq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "LATENT_DIM = 256\n",
        "EMBEDDING_DIM = 100\n",
        "MAX_NUM_WORDS = 20000\n",
        "NUM_SAMPLES = 10000\n",
        "EPOCHS = 40"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRqzJRNqLNrN",
        "colab_type": "text"
      },
      "source": [
        "Input Variable \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3S0SD1gkLQV8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_texts = []\n",
        "target_texts = []\n",
        "target_texts_inputs = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ejA8uLVMzJE",
        "colab_type": "code",
        "outputId": "07bdef66-e0f5-45fb-eb91-9dafe533961b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "t = 0\n",
        "for line in open('sample_data/fra.txt'):\n",
        "  # only keep a limited number of samples\n",
        "  t += 1\n",
        "  if t > NUM_SAMPLES:\n",
        "    break\n",
        "\n",
        "  # input and target are separated by tab\n",
        "  if '\\t' not in line:\n",
        "    continue\n",
        "\n",
        "  # split up the input and translation\n",
        "  line = line.rstrip().split('\\t')\n",
        "  input_text, translation = line[0], line[1]\n",
        "\n",
        "  if t < 10:\n",
        "    print(input_text, translation)\n",
        "\n",
        "  # make the target input and output\n",
        "  # recall we'll be using teacher forcing\n",
        "  target_text = translation + ' <eos>'\n",
        "  target_text_input = '<sos> ' + translation\n",
        "\n",
        "  input_texts.append(input_text)\n",
        "  target_texts.append(target_text)\n",
        "  target_texts_inputs.append(target_text_input)\n",
        "print(\"num samples:\", len(input_texts))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go. Va !\n",
            "Hi. Salut !\n",
            "Hi. Salut.\n",
            "Run! Cours !\n",
            "Run! Courez !\n",
            "Who? Qui ?\n",
            "Wow! Ça alors !\n",
            "Fire! Au feu !\n",
            "Help! À l'aide !\n",
            "num samples: 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tz9vSM54Pe4A",
        "colab_type": "code",
        "outputId": "1ceda2ce-7a87-439b-b746-e72efd9e3dc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "#tokenize the inputs\n",
        "tokenizer_inputs = Tokenizer(num_words=MAX_NUM_WORDS)\n",
        "tokenizer_inputs.fit_on_texts(input_texts)\n",
        "input_sequences = tokenizer_inputs.texts_to_sequences(input_texts)\n",
        "\n",
        "# get the word to index mapping for input language\n",
        "word2idx_inputs = tokenizer_inputs.word_index\n",
        "print('Found %s unique input tokens.' % len(word2idx_inputs))\n",
        "\n",
        "# determine maximum length input sequence\n",
        "max_len_input = max(len(s) for s in input_sequences)\n",
        "\n",
        "# tokenize the outputs\n",
        "# don't filter out special characters\n",
        "# otherwise <sos> and <eos> won't appear\n",
        "tokenizer_outputs = Tokenizer(num_words=MAX_NUM_WORDS, filters='')\n",
        "tokenizer_outputs.fit_on_texts(target_texts + target_texts_inputs) # inefficient, oh well\n",
        "target_sequences = tokenizer_outputs.texts_to_sequences(target_texts)\n",
        "target_sequences_inputs = tokenizer_outputs.texts_to_sequences(target_texts_inputs)\n",
        "\n",
        "# get the word to index mapping for output language\n",
        "word2idx_outputs = tokenizer_outputs.word_index\n",
        "print('Found %s unique output tokens.' % len(word2idx_outputs))\n",
        "\n",
        "# store number of output words for later\n",
        "# remember to add 1 since indexing starts at 1\n",
        "num_words_output = len(word2idx_outputs) + 1\n",
        "\n",
        "# determine maximum length output sequence\n",
        "max_len_target = max(len(s) for s in target_sequences)\n",
        "\n",
        "\n",
        "# pad the sequences\n",
        "encoder_inputs = pad_sequences(input_sequences, maxlen=max_len_input)\n",
        "print(\"encoder_inputs.shape:\", encoder_inputs.shape)\n",
        "print(\"encoder_inputs[0]:\", encoder_inputs[0])\n",
        "\n",
        "decoder_inputs = pad_sequences(target_sequences_inputs, maxlen=max_len_target, padding='post')\n",
        "print(\"decoder_inputs[0]:\", decoder_inputs[0])\n",
        "print(\"decoder_inputs.shape:\", decoder_inputs.shape)\n",
        "\n",
        "decoder_targets = pad_sequences(target_sequences, maxlen=max_len_target, padding='post')\n"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2146 unique input tokens.\n",
            "Found 5754 unique output tokens.\n",
            "encoder_inputs.shape: (10000, 5)\n",
            "encoder_inputs[0]: [ 0  0  0  0 15]\n",
            "decoder_inputs[0]: [ 2 57  4  0  0  0  0  0  0  0  0]\n",
            "decoder_inputs.shape: (10000, 11)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdnJOBvS6S4u",
        "colab_type": "code",
        "outputId": "a51d5465-ac48-414c-e6a3-fb511408018d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# store all the pre-trained word vectors\n",
        "print('Loading word vectors...')\n",
        "word2vec = {}\n",
        "with open('sample_data/glove.6B.%sd.txt' % EMBEDDING_DIM) as f:\n",
        "  # is just a space-separated text file in the format:\n",
        "  # word vec[0] vec[1] vec[2] ...\n",
        "  for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    vec = np.asarray(values[1:], dtype='float32')\n",
        "    word2vec[word] = vec\n",
        "print('Found %s word vectors.' % len(word2vec))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading word vectors...\n",
            "Found 386776 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INMTOP9NAsOt",
        "colab_type": "text"
      },
      "source": [
        "Prepare embedding matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJFp3GNXAklT",
        "colab_type": "code",
        "outputId": "5646831a-3f27-4f7d-a999-04efc9e87a6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Filling pre-trained embeddings...')\n",
        "num_words = min(MAX_NUM_WORDS, len(word2idx_inputs) + 1)\n",
        "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
        "for word, i in word2idx_inputs.items():\n",
        "  if i < MAX_NUM_WORDS:\n",
        "    embedding_vector = word2vec.get(word)\n",
        "    if embedding_vector is not None:\n",
        "      # words not found in embedding index will be all zeros.\n",
        "      embedding_matrix[i] = embedding_vector\n"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Filling pre-trained embeddings...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_VbSNAyBEHN",
        "colab_type": "text"
      },
      "source": [
        "Creating embedding layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkNT-ImQA21W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_layer = Embedding(\n",
        "  num_words,\n",
        "  EMBEDDING_DIM,\n",
        "  weights=[embedding_matrix],\n",
        "  input_length=max_len_input,\n",
        "  # trainable=True\n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_lKeYRzBG4P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create targets, since we cannot use sparse\n",
        "# categorical cross entropy when we have sequences\n",
        "decoder_targets_one_hot = np.zeros(\n",
        "  (\n",
        "    len(input_texts),\n",
        "    max_len_target,\n",
        "    num_words_output\n",
        "  ),\n",
        "  dtype='float32'\n",
        ")\n",
        "\n",
        "# assign the values\n",
        "for i, d in enumerate(decoder_targets):\n",
        "  for t, word in enumerate(d):\n",
        "    decoder_targets_one_hot[i, t, word] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbT4cGO2BUWt",
        "colab_type": "text"
      },
      "source": [
        "Build the model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9-OLtuaBNfD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_inputs_placeholder = Input(shape=(max_len_input,))\n",
        "x = embedding_layer(encoder_inputs_placeholder)\n",
        "encoder = LSTM(\n",
        "  LATENT_DIM,\n",
        "  return_state=True,\n",
        "  # dropout=0.5 # dropout not available on gpu\n",
        ")\n",
        "encoder_outputs, h, c = encoder(x)\n",
        "# encoder_outputs, h = encoder(x) #gru"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUcDkQGORqeL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_outputs, h, c = encoder(x)\n",
        "encoder_states = [h, c]\n",
        "\n",
        "# set up the decoder, using [h, c] as initial state \n",
        "# Set up the decoder, using [h, c] as initial state.\n",
        "decoder_inputs_placeholder = Input(shape=(max_len_target,))\n",
        "\n",
        "# this word embedding will not use pre-trained vectors\n",
        "# although you could\n",
        "decoder_embedding = Embedding(num_words_output, LATENT_DIM)\n",
        "decoder_inputs_x = decoder_embedding(decoder_inputs_placeholder)\n",
        "\n",
        "# since the decoder is a \"to-many\" model we want to have\n",
        "# return_sequences=True\n",
        "decoder_lstm = LSTM(\n",
        "  LATENT_DIM,\n",
        "  return_sequences=True,\n",
        "  return_state=True,\n",
        "  # dropout=0.5 # dropout not available on gpu\n",
        ")\n",
        "decoder_outputs, _, _ = decoder_lstm(\n",
        "  decoder_inputs_x,\n",
        "  initial_state=encoder_states\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXQkmky1rz1A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Create the model object\n",
        "model = Model(inputs = [encoder_inputs_placeholder, decoder_inputs_placeholder], outputs = decoder_outputs)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h88vNx8_ryW1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "def custom_loss(y_true, y_pred):\n",
        "  # both are of shape N x T x K\n",
        "  mask = K.cast(y_true > 0, dtype='float32')\n",
        "  out = mask * y_true * K.log(y_pred)\n",
        "  return -K.sum(out) / K.sum(mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "u3KbgP7WU6__",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c2dd5e3f-9e2e-46f7-f047-b13025f5b641"
      },
      "source": [
        "encoder_outputs, h, c = encoder(x)\n",
        "# encoder_outputs, h = encoder(x) #gru\n",
        "\n",
        "# keep only the states to pass into decoder\n",
        "encoder_states = [h, c]\n",
        "# encoder_states = [state_h] # gru\n",
        "\n",
        "# Set up the decoder, using [h, c] as initial state.\n",
        "decoder_inputs_placeholder = Input(shape=(max_len_target,))\n",
        "\n",
        "# this word embedding will not use pre-trained vectors\n",
        "# although you could\n",
        "decoder_embedding = Embedding(num_words_output, LATENT_DIM)\n",
        "decoder_inputs_x = decoder_embedding(decoder_inputs_placeholder)\n",
        "\n",
        "# since the decoder is a \"to-many\" model we want to have\n",
        "# return_sequences=True\n",
        "decoder_lstm = LSTM(\n",
        "  LATENT_DIM,\n",
        "  return_sequences=True,\n",
        "  return_state=True,\n",
        "  # dropout=0.5 # dropout not available on gpu\n",
        ")\n",
        "decoder_outputs, _, _ = decoder_lstm(\n",
        "  decoder_inputs_x,\n",
        "  initial_state=encoder_states\n",
        ")\n",
        "\n",
        "# decoder_outputs, _ = decoder_gru(\n",
        "#   decoder_inputs_x,\n",
        "#   initial_state=encoder_states\n",
        "# )\n",
        "\n",
        "# final dense layer for predictions\n",
        "decoder_dense = Dense(num_words_output, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Create the model object\n",
        "model = Model([encoder_inputs_placeholder, decoder_inputs_placeholder], decoder_outputs)\n",
        "\n",
        "\n",
        "def custom_loss(y_true, y_pred):\n",
        "  # both are of shape N x T x K\n",
        "  mask = K.cast(y_true > 0, dtype='float32')\n",
        "  out = mask * y_true * K.log(y_pred)\n",
        "  return -K.sum(out) / K.sum(mask)\n",
        "\n",
        "\n",
        "def acc(y_true, y_pred):\n",
        "  # both are of shape N x T x K\n",
        "  targ = K.argmax(y_true, axis=-1)\n",
        "  pred = K.argmax(y_pred, axis=-1)\n",
        "  correct = K.cast(K.equal(targ, pred), dtype='float32')\n",
        "\n",
        "  # 0 is padding, don't include those\n",
        "  mask = K.cast(K.greater(targ, 0), dtype='float32')\n",
        "  n_correct = K.sum(mask * correct)\n",
        "  n_total = K.sum(mask)\n",
        "  return n_correct / n_total\n",
        "\n",
        "model.compile(optimizer='adam', loss=custom_loss, metrics=[acc])\n",
        "\n",
        "# Compile the model and train it\n",
        "# model.compile(\n",
        "#   optimizer='rmsprop',\n",
        "#   loss='categorical_crossentropy',\n",
        "#   metrics=['accuracy']\n",
        "# )\n",
        "\n",
        "\n",
        "\n",
        "r = model.fit(\n",
        "  [encoder_inputs, decoder_inputs], decoder_targets_one_hot,\n",
        "  batch_size=BATCH_SIZE,\n",
        "  epochs=EPOCHS,\n",
        "  validation_split=0.2,\n",
        ")\n",
        "\n",
        "# plot some data\n",
        "plt.plot(r.history['loss'], label='loss')\n",
        "plt.plot(r.history['val_loss'], label='val_loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# accuracies\n",
        "plt.plot(r.history['acc'], label='acc')\n",
        "plt.plot(r.history['val_acc'], label='val_acc')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Save model\n",
        "model.save('s2s.h5')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##### Make predictions #####\n",
        "# As with the poetry example, we need to create another model\n",
        "# that can take in the RNN state and previous word as input\n",
        "# and accept a T=1 sequence.\n",
        "\n",
        "# The encoder will be stand-alone\n",
        "# From this we will get our initial decoder hidden state\n",
        "encoder_model = Model(encoder_inputs_placeholder, encoder_states)\n",
        "\n",
        "decoder_state_input_h = Input(shape=(LATENT_DIM,))\n",
        "decoder_state_input_c = Input(shape=(LATENT_DIM,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "# decoder_states_inputs = [decoder_state_input_h] # gru\n",
        "\n",
        "decoder_inputs_single = Input(shape=(1,))\n",
        "decoder_inputs_single_x = decoder_embedding(decoder_inputs_single)\n",
        "\n",
        "# this time, we want to keep the states too, to be output\n",
        "# by our sampling model\n",
        "decoder_outputs, h, c = decoder_lstm(\n",
        "  decoder_inputs_single_x,\n",
        "  initial_state=decoder_states_inputs\n",
        ")\n",
        "# decoder_outputs, state_h = decoder_lstm(\n",
        "#   decoder_inputs_single_x,\n",
        "#   initial_state=decoder_states_inputs\n",
        "# ) #gru\n",
        "decoder_states = [h, c]\n",
        "# decoder_states = [h] # gru\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# The sampling model\n",
        "# inputs: y(t-1), h(t-1), c(t-1)\n",
        "# outputs: y(t), h(t), c(t)\n",
        "decoder_model = Model(\n",
        "  [decoder_inputs_single] + decoder_states_inputs, \n",
        "  [decoder_outputs] + decoder_states\n",
        ")\n",
        "\n",
        "# map indexes back into real words\n",
        "# so we can view the results\n",
        "idx2word_eng = {v:k for k, v in word2idx_inputs.items()}\n",
        "idx2word_trans = {v:k for k, v in word2idx_outputs.items()}\n",
        "\n",
        "\n",
        "def decode_sequence(input_seq):\n",
        "  # Encode the input as state vectors.\n",
        "  states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "  # Generate empty target sequence of length 1.\n",
        "  target_seq = np.zeros((1, 1))\n",
        "\n",
        "  # Populate the first character of target sequence with the start character.\n",
        "  # NOTE: tokenizer lower-cases all words\n",
        "  target_seq[0, 0] = word2idx_outputs['<sos>']\n",
        "\n",
        "  # if we get this we break\n",
        "  eos = word2idx_outputs['<eos>']\n",
        "\n",
        "  # Create the translation\n",
        "  output_sentence = []\n",
        "  for _ in range(max_len_target):\n",
        "    output_tokens, h, c = decoder_model.predict(\n",
        "      [target_seq] + states_value\n",
        "    )\n",
        "    # output_tokens, h = decoder_model.predict(\n",
        "    #     [target_seq] + states_value\n",
        "    # ) # gru\n",
        "\n",
        "    # Get next word\n",
        "    idx = np.argmax(output_tokens[0, 0, :])\n",
        "\n",
        "    # End sentence of EOS\n",
        "    if eos == idx:\n",
        "      break\n",
        "\n",
        "    word = ''\n",
        "    if idx > 0:\n",
        "      word = idx2word_trans[idx]\n",
        "      output_sentence.append(word)\n",
        "\n",
        "    # Update the decoder input\n",
        "    # which is just the word just generated\n",
        "    target_seq[0, 0] = idx\n",
        "\n",
        "    # Update states\n",
        "    states_value = [h, c]\n",
        "    # states_value = [h] # gru\n",
        "\n",
        "  return ' '.join(output_sentence)\n",
        "\n",
        "\n",
        "\n",
        "while True:\n",
        "  # Do some test translations\n",
        "  i = np.random.choice(len(input_texts))\n",
        "  input_seq = encoder_inputs[i:i+1]\n",
        "  translation = decode_sequence(input_seq)\n",
        "  print('-')\n",
        "  print('Input:', input_texts[i])\n",
        "  print('Translation:', translation)\n",
        "\n",
        "  ans = input(\"Continue? [Y/n]\")\n",
        "  if ans and ans.lower().startswith('n'):\n",
        "    break\n",
        "\n"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 8000 samples, validate on 2000 samples\n",
            "Epoch 1/40\n",
            "8000/8000 [==============================] - 12s 2ms/step - loss: 2.8989 - acc: 0.1136 - val_loss: 2.3316 - val_acc: 0.2354\n",
            "Epoch 2/40\n",
            "8000/8000 [==============================] - 5s 647us/step - loss: 1.9349 - acc: 0.2837 - val_loss: 2.1760 - val_acc: 0.2617\n",
            "Epoch 3/40\n",
            "8000/8000 [==============================] - 5s 632us/step - loss: 1.7813 - acc: 0.3048 - val_loss: 2.1062 - val_acc: 0.2771\n",
            "Epoch 4/40\n",
            "8000/8000 [==============================] - 5s 631us/step - loss: 1.6743 - acc: 0.3410 - val_loss: 2.0528 - val_acc: 0.2999\n",
            "Epoch 5/40\n",
            "8000/8000 [==============================] - 5s 627us/step - loss: 1.5661 - acc: 0.3768 - val_loss: 1.9795 - val_acc: 0.3165\n",
            "Epoch 6/40\n",
            "8000/8000 [==============================] - 5s 626us/step - loss: 1.4577 - acc: 0.4083 - val_loss: 1.9374 - val_acc: 0.3297\n",
            "Epoch 7/40\n",
            "8000/8000 [==============================] - 5s 625us/step - loss: 1.3653 - acc: 0.4396 - val_loss: 1.8924 - val_acc: 0.3469\n",
            "Epoch 8/40\n",
            "8000/8000 [==============================] - 5s 622us/step - loss: 1.2769 - acc: 0.4660 - val_loss: 1.8413 - val_acc: 0.3838\n",
            "Epoch 9/40\n",
            "8000/8000 [==============================] - 5s 622us/step - loss: 1.1953 - acc: 0.4888 - val_loss: 1.8196 - val_acc: 0.3892\n",
            "Epoch 10/40\n",
            "8000/8000 [==============================] - 5s 623us/step - loss: 1.1217 - acc: 0.5084 - val_loss: 1.7993 - val_acc: 0.4010\n",
            "Epoch 11/40\n",
            "8000/8000 [==============================] - 5s 620us/step - loss: 1.0561 - acc: 0.5264 - val_loss: 1.7840 - val_acc: 0.4119\n",
            "Epoch 12/40\n",
            "8000/8000 [==============================] - 5s 623us/step - loss: 0.9963 - acc: 0.5419 - val_loss: 1.7668 - val_acc: 0.4241\n",
            "Epoch 13/40\n",
            "8000/8000 [==============================] - 5s 623us/step - loss: 0.9391 - acc: 0.5555 - val_loss: 1.7689 - val_acc: 0.4289\n",
            "Epoch 14/40\n",
            "8000/8000 [==============================] - 5s 621us/step - loss: 0.8852 - acc: 0.5705 - val_loss: 1.7587 - val_acc: 0.4381\n",
            "Epoch 15/40\n",
            "8000/8000 [==============================] - 5s 622us/step - loss: 0.8357 - acc: 0.5858 - val_loss: 1.7561 - val_acc: 0.4363\n",
            "Epoch 16/40\n",
            "8000/8000 [==============================] - 5s 620us/step - loss: 0.7896 - acc: 0.5983 - val_loss: 1.7581 - val_acc: 0.4451\n",
            "Epoch 17/40\n",
            "8000/8000 [==============================] - 5s 621us/step - loss: 0.7475 - acc: 0.6114 - val_loss: 1.7671 - val_acc: 0.4432\n",
            "Epoch 18/40\n",
            "8000/8000 [==============================] - 5s 621us/step - loss: 0.7086 - acc: 0.6237 - val_loss: 1.7697 - val_acc: 0.4494\n",
            "Epoch 19/40\n",
            "8000/8000 [==============================] - 5s 622us/step - loss: 0.6722 - acc: 0.6362 - val_loss: 1.7701 - val_acc: 0.4499\n",
            "Epoch 20/40\n",
            "8000/8000 [==============================] - 5s 619us/step - loss: 0.6373 - acc: 0.6484 - val_loss: 1.7830 - val_acc: 0.4485\n",
            "Epoch 21/40\n",
            "8000/8000 [==============================] - 5s 621us/step - loss: 0.6039 - acc: 0.6612 - val_loss: 1.7898 - val_acc: 0.4494\n",
            "Epoch 22/40\n",
            "8000/8000 [==============================] - 5s 621us/step - loss: 0.5740 - acc: 0.6747 - val_loss: 1.7987 - val_acc: 0.4476\n",
            "Epoch 23/40\n",
            "8000/8000 [==============================] - 5s 620us/step - loss: 0.5462 - acc: 0.6823 - val_loss: 1.7993 - val_acc: 0.4510\n",
            "Epoch 24/40\n",
            "8000/8000 [==============================] - 5s 620us/step - loss: 0.5185 - acc: 0.6948 - val_loss: 1.8045 - val_acc: 0.4548\n",
            "Epoch 25/40\n",
            "8000/8000 [==============================] - 5s 626us/step - loss: 0.4935 - acc: 0.7026 - val_loss: 1.8125 - val_acc: 0.4510\n",
            "Epoch 26/40\n",
            "8000/8000 [==============================] - 5s 628us/step - loss: 0.4699 - acc: 0.7138 - val_loss: 1.8203 - val_acc: 0.4490\n",
            "Epoch 27/40\n",
            "8000/8000 [==============================] - 5s 620us/step - loss: 0.4492 - acc: 0.7220 - val_loss: 1.8267 - val_acc: 0.4512\n",
            "Epoch 28/40\n",
            "8000/8000 [==============================] - 5s 622us/step - loss: 0.4277 - acc: 0.7322 - val_loss: 1.8243 - val_acc: 0.4529\n",
            "Epoch 29/40\n",
            "8000/8000 [==============================] - 5s 620us/step - loss: 0.4078 - acc: 0.7417 - val_loss: 1.8419 - val_acc: 0.4533\n",
            "Epoch 30/40\n",
            "8000/8000 [==============================] - 5s 621us/step - loss: 0.3888 - acc: 0.7504 - val_loss: 1.8410 - val_acc: 0.4541\n",
            "Epoch 31/40\n",
            "8000/8000 [==============================] - 5s 621us/step - loss: 0.3720 - acc: 0.7572 - val_loss: 1.8648 - val_acc: 0.4518\n",
            "Epoch 32/40\n",
            "8000/8000 [==============================] - 5s 620us/step - loss: 0.3562 - acc: 0.7648 - val_loss: 1.8774 - val_acc: 0.4521\n",
            "Epoch 33/40\n",
            "8000/8000 [==============================] - 5s 620us/step - loss: 0.3395 - acc: 0.7723 - val_loss: 1.8715 - val_acc: 0.4489\n",
            "Epoch 34/40\n",
            "8000/8000 [==============================] - 5s 619us/step - loss: 0.3246 - acc: 0.7806 - val_loss: 1.8810 - val_acc: 0.4531\n",
            "Epoch 35/40\n",
            "8000/8000 [==============================] - 5s 618us/step - loss: 0.3102 - acc: 0.7889 - val_loss: 1.8827 - val_acc: 0.4580\n",
            "Epoch 36/40\n",
            "8000/8000 [==============================] - 5s 619us/step - loss: 0.2971 - acc: 0.7957 - val_loss: 1.8883 - val_acc: 0.4564\n",
            "Epoch 37/40\n",
            "8000/8000 [==============================] - 5s 619us/step - loss: 0.2838 - acc: 0.8008 - val_loss: 1.9013 - val_acc: 0.4558\n",
            "Epoch 38/40\n",
            "8000/8000 [==============================] - 5s 617us/step - loss: 0.2724 - acc: 0.8048 - val_loss: 1.9092 - val_acc: 0.4551\n",
            "Epoch 39/40\n",
            "8000/8000 [==============================] - 5s 618us/step - loss: 0.2615 - acc: 0.8116 - val_loss: 1.9137 - val_acc: 0.4568\n",
            "Epoch 40/40\n",
            "8000/8000 [==============================] - 5s 620us/step - loss: 0.2505 - acc: 0.8162 - val_loss: 1.9158 - val_acc: 0.4532\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD6CAYAAACxrrxPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nywAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "-\n",
            "Input: Need I go on?\n",
            "Translation: puis-je y aller en premier ?\n",
            "Continue? [Y/n]Y\n",
            "-\n",
            "Input: He is a doctor.\n",
            "Translation: il est médecin.\n",
            "Continue? [Y/n]Y\n",
            "-\n",
            "Input: Run for it!\n",
            "Translation: taillez-vous !\n",
            "Continue? [Y/n]Y\n",
            "-\n",
            "Input: I'm gullible.\n",
            "Translation: je suis indigné.\n",
            "Continue? [Y/n]n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEb9nM3AiZaL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
